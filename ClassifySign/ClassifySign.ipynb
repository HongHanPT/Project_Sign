{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassifySign.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kTaGYJRh90k"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split as split_data\n",
        "import time"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FJq4fgmiYoL"
      },
      "source": [
        "## **Xây dựng mô hình**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrT0t3I9iFHp"
      },
      "source": [
        "def ClassifySignModel():\n",
        "    model = Sequential()\n",
        "    width = 32\n",
        "    height = 32\n",
        "    classes = 4\n",
        "    shape = (width, height, 3)\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=shape))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    learning_rate = 0.01\n",
        "    opt = SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return  model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qVwQPIAiVAt"
      },
      "source": [
        "## **Huấn luyện**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j0QL2cxi2EK"
      },
      "source": [
        "###  Chuẩn bị dữ liệu\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAEFgW4bizBZ",
        "outputId": "afb178f3-2af7-4360-bb41-267af6f206d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/ClassifySign-DL/ClassifySign\n",
        "data_path = '/content/drive/My Drive/ClassifySign-DL/ClassifySign/Data32x32'\n",
        "def create_data():\n",
        "    data= []\n",
        "    for directory in ['Fast', 'Slow','Start','Stop']:\n",
        "        image_path = os.path.join(data_path, directory)\n",
        "        if directory == 'Fast':\n",
        "            label = 0\n",
        "        elif directory == 'Slow':\n",
        "            label = 1\n",
        "        elif directory == 'Start':\n",
        "            label = 2\n",
        "        elif directory == 'Stop':\n",
        "            label =3\n",
        "        for img in tqdm(os.listdir(image_path)):\n",
        "            path = os.path.join(image_path, img)\n",
        "            img_data=cv.imread(path)\n",
        "            data.append([np.array(img_data), label])\n",
        "    shuffle(data)\n",
        "    np.save('data.npy', data)\n",
        "    return data"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ClassifySign-DL/ClassifySign\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-T_ajbKjcxy"
      },
      "source": [
        "### Tiến hành training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAe5pMSljp4x"
      },
      "source": [
        " def training(model):\n",
        "    model.summary()\n",
        "    aug = ImageDataGenerator(rotation_range=0.18, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n",
        "\n",
        "    dataX= create_data()\n",
        "\n",
        "    # Chia tập dữ liệu thành 2 phần\n",
        "    train, test = split_data(dataX, test_size=0.2, random_state=42)\n",
        "    image_train = np.array([i[0] for i in train])\n",
        "    label_train = [i[1] for i in train]\n",
        "    image_test = np.array([i[0] for i in test])\n",
        "    label_test = [i[1] for i in test]\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "    label_train = lb.fit_transform(label_train)\n",
        "    label_test = lb.fit_transform(label_test)\n",
        "    image_train = image_train.astype(\"float\") / 255.0\n",
        "    image_test = image_test.astype(\"float\") / 255.0\n",
        "    #print(dataX)\n",
        "\n",
        "    epochs = 10\n",
        "    batch_size = 16\n",
        "    print(\"Start training\")\n",
        "\n",
        "    checkpoint_path = \"training/cp.ckpt\"\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "    # Create a callback that saves the model's weights\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                   save_weights_only=True,\n",
        "                                   verbose=1, period=5)\n",
        "    # This may generate warnings related to saving the state of the optimizer.\n",
        "    # These warnings (and similar warnings throughout this notebook)\n",
        "    # are in place to discourage outdated usage, and can be ignored.\n",
        "\n",
        "    model.fit(image_train, label_train, epochs=10, validation_data =(image_test, label_test),batch_size=16, steps_per_epoch=image_train.shape[0]/batch_size)\n",
        "    #model.fit_generator(aug.flow(image_train, label_train, batch_size=batch_size), validation_data=(image_test, label_test), steps_per_epoch=x_train.shape[0]/batch_size, epochs=epochs, verbose=1, callbacks=[cp_callback])\n",
        "    model.save_weights(\"classifySign.h5\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytVnBIPPmCSw"
      },
      "source": [
        "### Thực hành nhận dạng vật thể"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht4LD7ECm48Y"
      },
      "source": [
        "def classify(image, boxe): # boxe = (x, y, xmax, ymax)\n",
        "    # # Create a basic model instance\n",
        "    # model = ClassifySignModel()\n",
        "\n",
        "    # checkpoint_path = \"training/cp.ckpt\"\n",
        "    # checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "    # # Loads the weights\n",
        "    # model.load_weights(checkpoint_path)\n",
        "\n",
        "    # Recreate the exact same model, including its weights and the optimizer\n",
        "    new_model = ClassifySignModel()\n",
        "    new_model.load_weights('classifySign.h5')\n",
        "\n",
        "    # Show the model architecture\n",
        "    new_model.summary()\n",
        "\n",
        "    def crop(img, coords):\n",
        "        x_max = coords[2]\n",
        "        x_min = coords[0]\n",
        "        y_max = coords[3]\n",
        "        y_min = coords[1]\n",
        "        crop_img = img[y_min:y_max, x_min:x_max]\n",
        "        return crop_img\n",
        "    def check_boxe():\n",
        "        if boxe[2] - boxe [0] <= 32:\n",
        "          print('Check False')\n",
        "          return False\n",
        "        if boxe[3] - boxe [1] <= 32:\n",
        "          print('Check False')\n",
        "          return False\n",
        "        print('Check True')\n",
        "        return True\n",
        "    classes = [\"Fast\", \"Slow\", \"Start\", \"Stop\"]\n",
        "    result = None\n",
        "    if check_boxe():\n",
        "        image = crop(image, boxe)\n",
        "        image=cv.resize(image,(32,32))\n",
        "        \n",
        "        cv2_imshow(image)\n",
        "        image = np.array(image)\n",
        "        image = image.astype(\"float\")/255.0\n",
        "\n",
        "        test = np.expand_dims(image, axis=0)\n",
        "        strt = time.time()\n",
        "        result = new_model.predict(test)  #---- OK, chua Ok do ham reshape\n",
        "        stp = time.time()\n",
        "        print(stp -strt)\n",
        "    return result, classes\n",
        "    \n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UvRPT-P5OuA"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFZ-MBTgpudo",
        "outputId": "b4ceb302-ddfb-4018-a78b-da57f264dce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        }
      },
      "source": [
        "model = ClassifySignModel()\n",
        "\n",
        "ima = cv.imread('/content/drive/My Drive/ClassifySign-DL/ClassifySign/0a.jpg')\n",
        "classify(ima, (32,60, 72, 120))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_216 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_324 (Activation)  (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_270 (Bat (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_217 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_325 (Activation)  (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_271 (Bat (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_108 (MaxPoolin (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_218 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_326 (Activation)  (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_272 (Bat (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_219 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_327 (Activation)  (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_273 (Bat (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_109 (MaxPoolin (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_54 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_328 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_274 (Bat (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 4)                 2052      \n",
            "_________________________________________________________________\n",
            "activation_329 (Activation)  (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 2,168,100\n",
            "Trainable params: 2,166,692\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "Check True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F04111E7BA8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.1997816562652588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.7140029e-03, 3.6418514e-05, 9.9824959e-01, 1.3085151e-08]],\n",
              "       dtype=float32), ['Fast', 'Slow', 'Start', 'Stop'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}